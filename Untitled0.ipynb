{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP6+0hKVQkfWe78Qji17OMj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mehr-unnisa/mainfile/blob/main/Untitled0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "fim5moYk5a0A",
        "outputId": "fe1419d9-d011-4628-a97c-de31dc46f8b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting agh_vqis\n",
            "  Downloading agh_vqis-3.2.1-py3-none-any.whl (2.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: matplotlib>=3.5.1 in /usr/local/lib/python3.10/dist-packages (from agh_vqis) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.22.3 in /usr/local/lib/python3.10/dist-packages (from agh_vqis) (1.25.2)\n",
            "Requirement already satisfied: pandas>=1.4.2 in /usr/local/lib/python3.10/dist-packages (from agh_vqis) (1.5.3)\n",
            "Collecting PIMS>=0.5 (from agh_vqis)\n",
            "  Downloading PIMS-0.6.1.tar.gz (86 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.0/86.0 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: scikit-image>=0.19.2 in /usr/local/lib/python3.10/dist-packages (from agh_vqis) (0.19.3)\n",
            "Collecting slicerator>=1.1.0 (from agh_vqis)\n",
            "  Downloading slicerator-1.1.0-py3-none-any.whl (10 kB)\n",
            "Collecting scenedetect>=0.6.0.3 (from agh_vqis)\n",
            "  Downloading scenedetect-0.6.2-py3-none-any.whl (117 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.1/117.1 kB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: opencv-python>=4.6.0.66 in /usr/local/lib/python3.10/dist-packages (from agh_vqis) (4.8.0.76)\n",
            "Collecting xgboost==1.7.5 (from agh_vqis)\n",
            "  Downloading xgboost-1.7.5-py3-none-manylinux2014_x86_64.whl (200.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.3/200.3 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting scikit-learn==1.2.0 (from agh_vqis)\n",
            "  Downloading scikit_learn-1.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.5/9.5 MB\u001b[0m \u001b[31m80.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting av>=9.0.0 (from agh_vqis)\n",
            "  Downloading av-11.0.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (32.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m32.9/32.9 MB\u001b[0m \u001b[31m33.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ffmpeg-python>=0.2.0 (from agh_vqis)\n",
            "  Downloading ffmpeg_python-0.2.0-py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==1.2.0->agh_vqis) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==1.2.0->agh_vqis) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==1.2.0->agh_vqis) (3.3.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from ffmpeg-python>=0.2.0->agh_vqis) (0.18.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5.1->agh_vqis) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5.1->agh_vqis) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5.1->agh_vqis) (4.48.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5.1->agh_vqis) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5.1->agh_vqis) (23.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5.1->agh_vqis) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5.1->agh_vqis) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5.1->agh_vqis) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.4.2->agh_vqis) (2023.4)\n",
            "Requirement already satisfied: imageio in /usr/local/lib/python3.10/dist-packages (from PIMS>=0.5->agh_vqis) (2.31.6)\n",
            "Requirement already satisfied: Click in /usr/local/lib/python3.10/dist-packages (from scenedetect>=0.6.0.3->agh_vqis) (8.1.7)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.10/dist-packages (from scenedetect>=0.6.0.3->agh_vqis) (4.2.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from scenedetect>=0.6.0.3->agh_vqis) (4.66.2)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.19.2->agh_vqis) (3.2.1)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.19.2->agh_vqis) (2024.2.12)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.19.2->agh_vqis) (1.5.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.5.1->agh_vqis) (1.16.0)\n",
            "Building wheels for collected packages: PIMS\n",
            "  Building wheel for PIMS (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for PIMS: filename=PIMS-0.6.1-py3-none-any.whl size=82615 sha256=de2e790a05a60aab14c68e06091df0d05776feb3df35aef2e30c26509090e10b\n",
            "  Stored in directory: /root/.cache/pip/wheels/cc/bf/3e/bfa77232d942f8244145f9c713b6b38f6ef04b6fb5c021c114\n",
            "Successfully built PIMS\n",
            "Installing collected packages: slicerator, scenedetect, ffmpeg-python, av, xgboost, scikit-learn, PIMS, agh_vqis\n",
            "  Attempting uninstall: xgboost\n",
            "    Found existing installation: xgboost 2.0.3\n",
            "    Uninstalling xgboost-2.0.3:\n",
            "      Successfully uninstalled xgboost-2.0.3\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.2.2\n",
            "    Uninstalling scikit-learn-1.2.2:\n",
            "      Successfully uninstalled scikit-learn-1.2.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "bigframes 0.21.0 requires scikit-learn>=1.2.2, but you have scikit-learn 1.2.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed PIMS-0.6.1 agh_vqis-3.2.1 av-11.0.0 ffmpeg-python-0.2.0 scenedetect-0.6.2 scikit-learn-1.2.0 slicerator-1.1.0 xgboost-1.7.5\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'VQIs_for_raw.pkl'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-22d1a01b8446>\u001b[0m in \u001b[0;36m<cell line: 38>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"VQIs_for_{dataset}.pkl\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m             \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Writing to disk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"VQIs_for_{dataset}.pkl\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m         \u001b[0mvqis\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Reading from disk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0;31m#Display the first five rows\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'VQIs_for_raw.pkl'"
          ]
        }
      ],
      "source": [
        "!pip install agh_vqis\n",
        "from agh_vqis import process_single_mm_file, VQIs\n",
        "from pathlib import Path\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import shutil\n",
        "# from sklearn.tree import DecisionTreeClassifier\n",
        "# import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "import pickle\n",
        "\n",
        "\n",
        "RECALC = False\n",
        "\n",
        "\n",
        "def read_vqis(my_file):\n",
        "    \"\"\"\n",
        "    :param my_file: The name of the file to be read.\n",
        "    :return: The data frame obtained from reading the CSV file.\n",
        "\n",
        "    This method reads a CSV file located in the specified directory path and with the given file name. It then\n",
        "    processes the contents of the file, adds a 'Frame' column with the value of * the file name, and removes the file\n",
        "    from the directory. Finally, it returns the resulting data frame.\n",
        "    \"\"\"\n",
        "    process_single_mm_file(Path(my_file))\n",
        "    my_df = pd.read_csv(\n",
        "        f\"VQIs_for_{my_file[my_file.rfind('/')+1:-3]}csv\"\n",
        "    )  # Load the CSV file\n",
        "    my_df[\"Frame\"] = my_file\n",
        "    os.remove(f\"VQIs_for_{my_file[my_file.rfind('/')+1:-3]}csv\")  # Remove the file\n",
        "    return my_df\n",
        "\n",
        "\n",
        "datasets = {\"raw\": \"src\", \"reference\": \"pvs\"}\n",
        "vqis = {}\n",
        "for dataset in datasets:\n",
        "    directory_path = datasets[dataset]  # Specify the directory path\n",
        "\n",
        "    if RECALC:\n",
        "        # file_list = [\n",
        "        #     file\n",
        "        #     for file in os.listdir(directory_path)\n",
        "        #     if os.path.isfile(os.path.join(directory_path, file))\n",
        "        # ]  # Create a list of files in the given directory\n",
        "\n",
        "        file_list = []\n",
        "        for root, dirs, files in os.walk(\n",
        "            directory_path\n",
        "        ):  # Create a list of files in the given directory\n",
        "            for file in files:\n",
        "                file_list.append(os.path.join(root, file))\n",
        "        # print(file_list)\n",
        "        # exit(0)\n",
        "\n",
        "        df = read_vqis(file_list[0])\n",
        "\n",
        "        for file in file_list[1:]:\n",
        "            new_row = read_vqis(file)\n",
        "            df = pd.concat(\n",
        "                [df, new_row], axis=0\n",
        "            )  # Add the new row to the existing DataFrame\n",
        "\n",
        "        with open(f\"VQIs_for_{dataset}.pkl\", \"wb\") as f:\n",
        "            pickle.dump(df, f)  # Writing to disk\n",
        "    with open(f\"VQIs_for_{dataset}.pkl\", \"rb\") as f:\n",
        "        vqis[dataset] = pickle.load(f)  # Reading from disk\n",
        "    #Display the first five rows\n",
        "    #print(vqis[dataset].head())\n",
        "    print(vqis[dataset].describe())\n",
        "y_raw = pd.DataFrame(\n",
        "    {\"Class\": [\"raw\"] * vqis[\"raw\"].shape[0]}\n",
        ")  # Create a DataFrame with one column and rows with the 'raw' value\n",
        "y_ref = pd.DataFrame(\n",
        "    {\"Class\": [\"reference\"] * vqis[\"reference\"].shape[0]}\n",
        ")  # Create a DataFrame with one column and rows with the 'reference' value\n",
        "x = pd.concat([vqis[\"raw\"], vqis[\"reference\"]], axis=0)\n",
        "y = pd.concat([y_raw, y_ref], axis=0)\n",
        "#del x[\"Frame\"]\n",
        "del x[\"Slice\"]\n",
        "print(x)\n",
        "print(y)\n",
        "print(y.describe())\n",
        "print(y.value_counts())\n",
        "print(type(y))\n",
        "# y[\"Class\"] = np.random.choice([\"raw\", \"reference\"], size=len(y))\n",
        "# print(y.value_counts())\n",
        "# print(y.describe())\n",
        "# clf = DecisionTreeClassifier()\n",
        "print(\"-----------------------------------------------------------------------\")\n",
        "print(x.iloc[:,1:])\n",
        "clf = RandomForestClassifier()\n",
        "clf.fit(x.iloc[:,1:], y)\n",
        "print(clf.feature_importances_)\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)\n",
        "\n",
        "print(x_train.shape, y_train.shape)\n",
        "print(x_test.shape, y_test.shape)\n",
        "clf.fit(x_train.iloc[:,1:], y_train)\n",
        "print(clf.score(x_test.iloc[:,1:], y_test))\n",
        "\n",
        "print(\"+++++++++++++++++++++++++++++++++++++\")\n",
        "#print(x.iloc[[5]])\n",
        "df1=x_test['Frame']\n",
        "del x_test[\"Frame\"]\n",
        "\n",
        "for i in range(0,len(x_test)):\n",
        "\n",
        "    pred=clf.predict(x_test.iloc[[i]])\n",
        "    print(pred)\n",
        "    actual = y_test.iloc[[i]]\n",
        "    print(actual)\n",
        "    print(\"======================\",df1.values[i])\n",
        "    source = df1.values[i] # Assuming you want the file path from the 6th row\n",
        "    # Construct the source and destination paths\n",
        "    source_path = f\"{source}\"\n",
        "\n",
        "    if pred != actual.values:\n",
        "        if actual.values == \"raw\":\n",
        "            shutil.copy(source_path, 'wrong prediction/raw/')\n",
        "        else:\n",
        "            shutil.copy(source_path, 'wrong prediction/reference/')"
      ]
    }
  ]
}